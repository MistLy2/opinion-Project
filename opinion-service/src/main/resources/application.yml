server:
  port: 8082
#  用postman接口测试时，这里的端口要默认是80，否则会无法连接

spring:
  application:
    name: opinion-service
  datasource:
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://localhost:3306/db_opinion?serverTimezone=Asia/Shanghai&useUnicode=true&
        characterEncoding=utf-8&useSSL=false
      username: root
      password:
  kafka:
    producer:
      bootstrap-servers: localhost:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer: # consumer消费者
      group-id: mentugroup # 默认的消费组ID
      enable-auto-commit: true # 是否自动提交offset
      auto-commit-interval: 100  # 提交offset延时(接收到消息后多久提交offset)
      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer:  org.springframework.kafka.support.serializer.JsonDeserializer

      batch-size: 131072  #128kb
      buffer-memory: 67108864 #64M
      #max-request-size: 5242880
      #linger-ms: 5
      retries: 1
      acks: 0
      compression-type: gzip  #提升性能很重要
      properties:
#        注意kafka要配置信任文件，*表示信任所有文件
        spring:
          json:
            trusted:
              packages: '*'
        max.request.size: 5242880 #5M
        linger.ms: 5
  redis:
    host: localhost
    port: 6379
    #password: 123456  如果有密码就需要
    database: 0
    jedis:
      pool:
        max-active: 8
        max-idle: 4
        min-idle: 0
        max-wait: 1ms #连接池最大阻塞等待时间
  cache:
    redis:
      time-to-live: 1800000 #设置缓存数据的缓存时间

  view:
    prefix: /
    suffix: .html
#  mvc:
#    view:
#      prefix: /
#      suffix: .html
##      视图解析器配置



mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    map-underscore-to-camel-case: true
  global-config:
    db-config:
      id-type: ASSIGN_ID
#      这里要注意一定要设置id为自增，系统默认为雪花算法形成的无规则id
# 进行一个mp日志的打印,设置为标准输出流打印,开启日志后就能看到mp执行过程和sql执行过程
